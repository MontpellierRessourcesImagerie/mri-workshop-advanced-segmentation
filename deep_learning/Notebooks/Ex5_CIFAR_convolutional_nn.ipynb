{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex5_CIFAR_convolutional_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rG-8LoDgv8Y"
      },
      "source": [
        "# Optimization of a CNN to classify RGB images\n",
        "\n",
        "The goal of this exercice is to train and optimize an artificial neural network on images from the [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) database. In that case, the images are classifiy according to 10 different classes : airplane, car, truck, bird, cat, dog, deer, horse, frog and ship. \n",
        "There is several difficulties in that case :\n",
        "- several classes are quite close (such as car and truck) and will require a thourough training of the network to efficiently differentiate the images\n",
        "- the images are RGB and of very low quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aujvzaCgv8b"
      },
      "source": [
        "## I - Downloading the CIFAR image database\n",
        "\n",
        "First step - we will all the necessary libraries.\n",
        "\n",
        "**Exercise** :\n",
        "- from tensorflow, import keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC5FoN7Cgv8c"
      },
      "source": [
        "# to show images directly in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# to display tensorboard directly in the notebook\n",
        "# %load_ext tensorboard\n",
        "\n",
        "import numpy as np    # scientific computing \n",
        "import matplotlib.pyplot as plt   # plotting and visualisation\n",
        "import random \n",
        "\n",
        "# import keras and its libraries\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow import ###\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVZcLDPP-8sM"
      },
      "source": [
        "Then we import the CIFAR database and display few examples. \n",
        "\n",
        "**Exercise** :\n",
        "- from keras import the cifar10 image dataset\n",
        "- load the training and testing dataset\n",
        "- plot 9 images in a 3x3 layout by randomly selecting data from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D27M16WO_FPZ"
      },
      "source": [
        "from keras.datasets import ###\n",
        "\n",
        "(X_train, y_train), (X_val, y_val) = ###\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (5,5) # Define the figure size\n",
        "for i in range(9):\n",
        "\n",
        "###\n",
        "    \n",
        "plt.tight_layout()\n",
        "\n",
        "print('')\n",
        "print('The CIFAR database contains {} images for training and {} images for testing/validation'.format(len(X_train), len(X_val)))\n",
        "print('X_train/X_val are composed of four dimensions. For example, X_train is {} and are respectively:'.format(X_train.shape))\n",
        "print('- the number of images in the database')\n",
        "print('- the 2D size of the images')\n",
        "print('- the number of channels (for example the images are RGB and contain 3 channels)')\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S24FWBQDKGJ"
      },
      "source": [
        "im = X_train[0]\n",
        "print('The size of the image is {} pixels'.format(im.shape))\n",
        "print('The minimum pixel value is {} and the maxium  {}'.format(np.min(im), np.max(im)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC1mo2Bk2T5K"
      },
      "source": [
        "## II - Formatting the data\n",
        "\n",
        "As already discussed for the MNIST, we need to normalize the images before working with them. In the case of the CIFAR database, the images are composed of 3 channels (RGB) and **each channel needs to be normalized separately**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHnZV1ZA3W2g"
      },
      "source": [
        "# calculate for each channel the average and std\n",
        "# -----------------------------------------------\n",
        "\n",
        "X_train = X_train.astype(float)/255\n",
        "X_val = X_val.astype(float)/255\n",
        "\n",
        "Er = np.mean(X_train[:,:,:,0])\n",
        "Eg = np.mean(X_train[:,:,:,1])\n",
        "Eb = np.mean(X_train[:,:,:,2])\n",
        "\n",
        "sr = np.std(X_train[:,:,:,0])\n",
        "sg = np.std(X_train[:,:,:,1])\n",
        "sb = np.std(X_train[:,:,:,2])\n",
        "\n",
        "# Normalize data so that average is zero and std 1\n",
        "# ------------------------------------------------\n",
        "\n",
        "X_train[:,:,:,0] = (X_train[:,:,:,0]-Er)/sr\n",
        "X_train[:,:,:,1] = (X_train[:,:,:,1]-Eg)/sg\n",
        "X_train[:,:,:,2] = (X_train[:,:,:,2]-Eb)/sb\n",
        "\n",
        "X_val[:,:,:,0] = (X_val[:,:,:,0]-Er)/sr\n",
        "X_val[:,:,:,1] = (X_val[:,:,:,1]-Eg)/sg\n",
        "X_val[:,:,:,2] = (X_val[:,:,:,2]-Eb)/sb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsI6iIul4dXJ"
      },
      "source": [
        "The labels are also changed from **single digit** to **categorical or one-hot format**.\n",
        "Exercise :\n",
        "- convert the training labels in the one-hot format\n",
        "- do the same for the validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-1wQ484uMo"
      },
      "source": [
        "from keras.utils import np_utils  # NumPy related tools\n",
        "\n",
        "Y_train = ###\n",
        "Y_val = ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcQk1xYF6Qjq"
      },
      "source": [
        "## III- Creating and training a simple network for digit classification\n",
        "\n",
        "We will now build a CNN network able to read the CIFAR images as input and return a vector indicating the predicted class for each image. \n",
        "\n",
        "**Exercise** :\n",
        "- import the module Sequential to build sequential neural networks\n",
        "- import the layers you will need to build your models\n",
        "- create your model\n",
        "- select the optimize\n",
        "- select the loss function\n",
        "- select the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ffXLwr96zRx"
      },
      "source": [
        "from keras.models import ### # Model sequential to be used\n",
        "from keras.layers import ###\n",
        "\n",
        "modelCNN = Sequential([\n",
        "\n",
        "### Complete your network\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model defining the optimizer and the loss function \n",
        "# --------------------------------------------------------------\n",
        "\n",
        "modelCNN.compile(optimizer = ###, \n",
        "              loss= ###,\n",
        "              metrics= ###)\n",
        "\n",
        "# Return a full description of the network\n",
        "# ----------------------------------------\n",
        "modelCNN.summary()\n",
        "\n",
        "# Create the image augmentation generator\n",
        "# ---------------------------------------\n",
        "\n",
        "# datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "# it_train = datagen.flow(X_train, Y_train, batch_size=32)\n",
        "# steps = int(X_train.shape[0] / 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICggImgs9nGi"
      },
      "source": [
        "And train it !\n",
        "\n",
        "**Exercise** :\n",
        "- define the fit functions with the proper training and validation data\n",
        "- select 10 epochs\n",
        "- select a batchsize of of 32 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmapQB9s-SEH"
      },
      "source": [
        "#from keras.callbacks import TensorBoard  #Visulization of Accuracy and loss\n",
        "#\n",
        "## tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "#%load_ext tensorboard\n",
        "#\n",
        "#tb_FC = TensorBoard('runs/CIFAR_v1', histogram_freq=1)\n",
        "#%tensorboard --logdir runs\n",
        "\n",
        "history = ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej8By2ntgv8-"
      },
      "source": [
        "## IV- Evaluate the model accuracy :\n",
        "\n",
        "Calculate the accuracy of the model using the test set.\n",
        "Exercise : \n",
        "- evaluate the accuracy of your model using the validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy4VkBkXgv8-"
      },
      "source": [
        "test_loss, test_acc = ###\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NclrPuMjFSzo"
      },
      "source": [
        "It is always useful to check the performance of the network on randomly selected images. More precisely, to improve our network, we need to understand why the network is sometimes failing. \n",
        "Below, we are going to test the network on the validation set and select images for which the network prediction is right and other for which the predition is wrong.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV3X38OjGbEN"
      },
      "source": [
        "# The predict_classes function outputs the highest probability class\n",
        "# according to the trained classifier for each input example.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "predicted_classes = modelCNN.predict(X_val)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "\n",
        "# Check which items we got right / wrong\n",
        "# --------------------------------------\n",
        "\n",
        "correct_indices = np.nonzero(predicted_classes == y_val[:,0])[0]\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_val[:,0])[0]\n",
        "\n",
        "print(len(correct_indices))\n",
        "print(len(incorrect_indices))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNuM9lsIhXS"
      },
      "source": [
        "Display a few example for which the network is right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMx_RIXiIpRI"
      },
      "source": [
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:3]):\n",
        "    plt.subplot(3,1,i+1)\n",
        "    plt.imshow(X_val[correct], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_val[correct][0]))\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNdp6TDeIzjy"
      },
      "source": [
        "... and a few where the network is wrong!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abXlRVKKIyuy"
      },
      "source": [
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:3]):\n",
        "    plt.subplot(3,1,i+1)\n",
        "    plt.imshow(X_val[incorrect], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_val[incorrect][0]))\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yHZwPnMvMWw"
      },
      "source": [
        "## V- Network performances\n",
        "\n",
        "Below the learning curves are displayed : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOjWIe4_TyPg"
      },
      "source": [
        "history_dict = history.history\n",
        "plt.rcParams['figure.figsize'] = (10,10) # Make the figures a bit bigger\n",
        "\n",
        "# Plot the evolution of the accuracy during the training\n",
        "# ------------------------------------------------------\n",
        "\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "n = len(acc_values)\n",
        "epochs = range(1, n+1)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the evolution of the loss during the training\n",
        "# ------------------------------------------------------\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em2dNu9IvNo6"
      },
      "source": [
        "Since we are working with 10 different categories, it is often useful to look at the performances of the network for each category. Below, two different tools are used to display the results :\n",
        "- **classification report** is creating a small summary of the network performances for each category, using different metrics\n",
        "- **confusion matrix** is returning a matrix indicating for each classes the propotion of true positive detections as well as the proportions of false negative and to which classes they are assigned. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCkRhY0WvQCo"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "target_names = ['aiplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print('Classification report :')\n",
        "print('')\n",
        "print(classification_report(np.argmax(Y_val, axis=1), predicted_classes, target_names=target_names))\n",
        "\n",
        "print('')\n",
        "print('Confusion matrix :')\n",
        "print('')\n",
        "print(np.around(confusion_matrix(np.argmax(Y_val, axis=1), predicted_classes)/1000,2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}