{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Ex6_RBC_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQRNRzBUrmIx"
      },
      "source": [
        "# Red blood cell classifier : practical application of a convNet\n",
        "\n",
        "With this example, you will build your own convNet in order to perform a specific task : classifying images of red blood cells (RBC) of either good or bad quality.\n",
        "\n",
        "Data were kindly given by Viviana Claveria & Manouk Abkarian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XbYo16drmJE"
      },
      "source": [
        "## I - Data importation\n",
        "\n",
        "The data are RGB images saved in the png format on a google drive. All images are already sorted according to two classes :\n",
        "- good RBC (1)\n",
        "- bad RBC (0)\n",
        "\n",
        "\n",
        "The first step is to load all the python packages we will use in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EQkNfa8rmJG"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import random\n",
        "import sys\n",
        "import warnings\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pE-vsf3ujF-"
      },
      "source": [
        "Connect google drive to google collab and move to the folder containing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7ObWPAsDsd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "base_dir = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/'\n",
        "os.chdir(base_dir)\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdZ9rx8Jo8oc"
      },
      "source": [
        "Since all the images are different and do not have the same X,Y dimensions we will define a set of parameters to homogeneize the training/testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo2UsUAB5SvP"
      },
      "source": [
        "# Set the image size\n",
        "# -----------------\n",
        "IMG_WIDTH = 70\n",
        "IMG_HEIGHT = 70\n",
        "IMG_CHANNEL = 3\n",
        "\n",
        "# Define the path where the data are saved\n",
        "# ----------------------------------------\n",
        "\n",
        "goodRBC_train_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/train/goodRBC/'\n",
        "badRBC_train_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/train/badRBC/'\n",
        "\n",
        "goodRBC_val_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/validation/goodRBC/'\n",
        "badRBC_val_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/validation/badRBC/'\n",
        "\n",
        "goodRBC_test_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/test/goodRBC/'\n",
        "badRBC_test_PATH = '/content/gdrive/My Drive/Deep_learning_formation_MRI/Doc_JB_2021/Divers_part2/RBC_database/test/badRBC/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnpIfpz2pXMM"
      },
      "source": [
        "The following method **get_data** is used to download the image and convert it to the right format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqVGyk4G_1px"
      },
      "source": [
        "def get_data(path):\n",
        "\n",
        "  # get the total number of samples\n",
        "  # -------------------------------\n",
        "\n",
        "  ids = next(os.walk(path))[2]\n",
        "  X = np.zeros((len(ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\n",
        "\n",
        "  sys.stdout.flush()\n",
        "  \n",
        "  # select only the first n_im images\n",
        "  # ---------------------------------\n",
        "\n",
        "  for n, id_ in tqdm(enumerate(ids), total=len(ids)):\n",
        "    path_new = path + id_\n",
        "\n",
        "    # we'll be using skimage library for reading file and make sure all the images\n",
        "    # have the same dimensions\n",
        "    # -------------------------\n",
        "\n",
        "    img = imread(path_new)\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "\n",
        "    if len(img.shape) == 3:\n",
        "      X[n] = img\n",
        "    else:\n",
        "      img = np.stack((img,)*3, axis=-1)\n",
        "      X[n] = img\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rehyVFIpx6b"
      },
      "source": [
        "The training and testing set are defined below. Note that we are also building the ground truth accordingly.\n",
        "**Note that it takes ~20-30min to load the data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALHaQ8Aj_6S2"
      },
      "source": [
        "Good_RBC = get_data(goodRBC_train_PATH)\n",
        "y_good = np.ones((Good_RBC.shape[0],))\n",
        "Bad_RBC = get_data(badRBC_train_PATH)\n",
        "y_bad = np.zeros((Bad_RBC.shape[0],))\n",
        "\n",
        "X_train = np.concatenate((Good_RBC,Bad_RBC), axis=0)\n",
        "Y_train = np.concatenate((y_good,y_bad), axis=0)\n",
        "\n",
        "\n",
        "Good_RBC_test = get_data(goodRBC_test_PATH)\n",
        "y_good = np.ones((Good_RBC_test.shape[0],))\n",
        "Bad_RBC_test = get_data(badRBC_test_PATH)\n",
        "y_bad = np.zeros((Bad_RBC_test.shape[0],))\n",
        "\n",
        "X_test = np.concatenate((Good_RBC_test,Bad_RBC_test), axis=0)\n",
        "Y_test = np.concatenate((y_good,y_bad), axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NUf3R0KeH4L"
      },
      "source": [
        "Return the composition of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tncgWMRneG3h"
      },
      "source": [
        "print('The train dataset is composed of {} images belonging to the \"goodRBC\" class and {} images belonging to the \"badRBC\" class'.format(Good_RBC.shape[0],Bad_RBC.shape[0]))\n",
        "print('The test dataset is composed of {} images belonging to the \"goodRBC\" class and {} images belonging to the \"badRBC\" class'.format(Good_RBC_test.shape[0],Bad_RBC_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBjungtpfIn7"
      },
      "source": [
        "And finally make sure the data are normalized : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvOaL70HfO9u"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnWY37lJ1bmd"
      },
      "source": [
        "## II- Data vizualization :\n",
        "\n",
        "Display a few examples of images belonging to the \"GoodRBC\" class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYidlV5Gvk7j"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (5,5) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(Good_RBC))\n",
        "    im = Good_RBC[num]\n",
        "    plt.imshow(im)\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnV8EAur1klZ"
      },
      "source": [
        "And the same for the \"BadRBC\" class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKs348GS1ot4"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (5,5) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(Bad_RBC))\n",
        "    im = Bad_RBC[num]\n",
        "    plt.imshow(im)\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST02zYbxrmJP"
      },
      "source": [
        "## III- Definition of the model and training\n",
        "\n",
        "Define the model and the compilation options. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzV8Z8nyrmJQ"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(70,70,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam', \n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvXQjHmsrmJR"
      },
      "source": [
        "Define the model and the compilation options. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duPj2CGOrmJS"
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size = 32,\n",
        "                    epochs = 25,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl9W_ynNrmJW"
      },
      "source": [
        "Display the loss function during the training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYto0pbGrmJW"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "n = len(loss_values)\n",
        "epochs = range(1, n+1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00hpazBzrmJY"
      },
      "source": [
        "The accuracy of the model is tested using the testing set of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DqMUUdHrmJY"
      },
      "source": [
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "n = len(acc_values)\n",
        "epochs = range(1, n+1)\n",
        "\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acccuracy')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNDvol02smgM"
      },
      "source": [
        "## IV- Transfer learning\n",
        "\n",
        "In the following section, we will see how transfer learning can be used to improve the performances of a classifier. The idea is to  used a previously trained network (such as VGG16) that was already trained on thousands of images and able to recognize hundred of thousands of different features on images.\n",
        "\n",
        "By adding new layers at the end of the pre-trained network, we can use the features recognition property of this network and applied it to a completely new problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6a8KNvUuSTd"
      },
      "source": [
        "The first step is to load the pre-trained VGG16 network. There are many different available model in keras (https://keras.io/api/applications/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p08M5dZwsl1X"
      },
      "source": [
        "from keras.applications import vgg16\n",
        "conv_base = vgg16.VGG16(weights='imagenet',include_top = False,input_shape=(50,50,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODAvzNKiup2p"
      },
      "source": [
        "And then we will build our model around the VGG16 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTuh0eMpuvMb"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "conv_base.trainable = False\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaz6DPmWuzJf"
      },
      "source": [
        "We need to define which part of the network will be trained. In our case, only the last convolution block of the VGG and the densely connected part will be trained :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ugjEmuTu3fM"
      },
      "source": [
        "conv_base.trainable = False\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if layer.name == 'block5_conv2':\n",
        "        set_trainable = True\n",
        "    if layer.name == 'block5_conv3':\n",
        "        set_trainable = True \n",
        "            \n",
        "model.compile(optimizer = 'adam', \n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObsKCEasvqMJ"
      },
      "source": [
        "And finally train the new model and save it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJTOzDafvmPb"
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size = 64,\n",
        "                    epochs = 25,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    shuffle = True)\n",
        "\n",
        "\n",
        "# Save the model\n",
        "# --------------\n",
        "\n",
        "model.save('RBC_classification_VGG16_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}