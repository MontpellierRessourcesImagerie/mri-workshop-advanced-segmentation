{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Identify the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image set is of a Transfluor assay where an orphan GPCR is stably integrated into the b-arrestin GFP expressing U2OS cell line. After one hour incubation with a compound the cells were fixed with (formaldehyde).\n",
    "\n",
    "![](./exercises/svm/images/images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels in the data are discrete, the predication falls into two categories, (i.e. Postive cell or Negative Cell). In machine learning this is a classification problem.    \n",
    "> Thus, the goal is to classify whether cell  is positive or negative and predict the accuracy of the model with different kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Identify data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used image set [BBBC016v1](https://data.broadinstitute.org/bbbc/BBBC016/) provided by Ilya Ravkin, available from the Broad Bioimage Benchmark Collection [Ljosa et al., Nature Methods, 2012].   \n",
    "We used a part of this dataset taking account the wells O06, O07, O16 and O22.    \n",
    "Features were generated by CellProfiler and classes were annotated manually. The dataset contains **40 samples of positives and negatives cells**.\n",
    "* The first two columns in the dataset contain the *labels* (Positives, Negatives), and the *dose* put for each well.\n",
    "* The columns 4 - 5 contain the well position on the plate, the unique ID of the image and the number of object respectively.\n",
    "* The columns 6 - 155 contain *features* that have been computed from images of the cell nuclei and cell cytoplasm which can be used to build a model to predict the phenotype of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Importing libraries.\n",
    "import numpy as np\n",
    "\n",
    "# b) Replace the occurences of ... to import the pandas library with the clause import. \n",
    "... ... as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Importing the dataset.\n",
    "\n",
    "# Replace the occurences of ... to indicate a string path to your file (ie dataset.csv). \n",
    "# Example A local file could be: \"C://localhost/path/to/table.csv\".\n",
    "file = ...\n",
    "\n",
    "# Replace the occurences of ... to load the dataset.csv file (path assigned previously) \n",
    "# using the Pandas read_csv function. \n",
    "dataset = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to visually inspect the dataset. There are multiple ways to achieve this:\n",
    "* The easiest being to request the first few records using the data.head() method. By default, “data.head()” returns the first 5 rows.\n",
    "* Alternatively, one can also use “data.tail()” to return the five rows of the data.\n",
    "* For both head and tail methods, there is an option to specify the number of rows by including the required number in between the parentheses when calling either method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) print the dataset.\n",
    "# After reading the notes above try to display the ten rows of the dataset. Fill in the occurences of ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the number of cases, as well as the number of fields, using the shape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) Replace the occurence ... by the shape method to get the number of rows and number of columns\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result displayed, you should be have 40 records with 155 columns.   \n",
    "The “info()” method provides a concise summary of the data; from the output, it provides the type of data in each column, the number of non-null values in each column, and how much memory the data frame is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) Replace the occurence ... by the \"info(verbose = True)\" to get the data type of each column\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above Label, Dose and Well are *categorical variables* and rest are floating or integer values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is a crucial step for any data analysis problem. It is often a very good idea to prepare your data in such way to best expose the structure of the problem to the machine learning algorithms that you intend to use. This involves a number of activities such as:\n",
    "* Assigning numerical values to categorical data.\n",
    "* Handling missing values.\n",
    "* Divide data into attributes and labels sets.\n",
    "* Divide data into traininig and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The goal here is encoding the class Label in an array y and get attributes in an array X. Then split the data into a *training set* and *testing set*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 split features and labels into new sets and encoding the labels into integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Use the method drop(columns=['feature_1', \"feature_2\", ...]) \n",
    "# to drop unnecessary features 'Label', 'Dose', 'Well', 'ImageNumber', 'ObjectNumber'\n",
    "# and affect the output to X variable\n",
    "... = ...\n",
    "\n",
    "# b) For select a feature use data['feature']. Replace the occurence ... to select the Label feature\n",
    "y = ...\n",
    "\n",
    "#transform the class labels from their original string representation (positive and negative) into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# c) Replace the occurence ... to display 5 rows of the X dataset with head() method\n",
    "print(..., y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After encoding the Label in an array y, the phenotype cell are now represented as class 1(i.e positive cell) and as class 0 (i.e negative cell), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. Here \n",
    "* Split the available data into a training set and a testing set. (70% training, 30% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Use the train_test_split method from the model.selection of scikit-learn.\n",
    "# Import the train_test_split method\n",
    "# This method takes three parameters train_test_split(param1, param2, param3). \n",
    "# The first parameter will be the X dataset, the second parameter will be the y dataset \n",
    "# and the third parameter will be the size of the testing set ie (70% = 0.70).\n",
    "# Fill in the occurences ...\n",
    "\n",
    "from sklearn.model_selection import ...\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(..., ..., test_size = ...)\n",
    "\n",
    "# b) Fill in the occurences ... to display the number of rows \n",
    "# and numbers of columns for the two variables (X_train and X_test)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictive model using Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernelized support vector machines are powerful models and perform well on a variety of datasets.\n",
    "\n",
    "   1. SVMs allow for *complex decision boundaries*, even if the data has only a few features.\n",
    "\n",
    "   2. They work well on *low-dimensional* and *high-dimensional* data (i.e., few and many features), but don’t scale very well with the number of samples.\n",
    "\n",
    "   3. SVMs requires careful *preprocessing of the data* and *tuning* of the parameters. This is why, these days, most people instead use tree-based models such as *random forests* or *gradient boosting* (which require little or no preprocessing) in many applications.\n",
    "   \n",
    "   4. SVM models are *hard to inspect*; it can be difficult to understand why a particular prediction was made, and it might be tricky to explain the model to a non-expert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The goal is to fit a linear model to the data using *SVC library* from the svm of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the instructions and fill in the occurences ...\n",
    "\n",
    "# a) Create an SVM classifier and train it on 70% of the data set.\n",
    "# use the support vector classifier class, which is written as SVC in the Scikit-Learn's svm library. \n",
    "# This class takes one parameter, which is the kernel type 'linear'.\n",
    "# We will see non-linear kernels in the next section.\n",
    "\n",
    "from sklearn.svm import ...\n",
    "svclassifier = ...(kernel= ... )\n",
    "\n",
    "# b) The fit method of SVC class is called to train the algorithm on the training data (X_train, y_train), \n",
    "# which is passed as a parameter to the fit method.\n",
    "\n",
    "...(... , ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result you will see the important parameters in kernel SVMs:\n",
    "* Regularization parameter C.\n",
    "\n",
    "* The choice of the kernel (linear, radial basis function(RBF) or polynomial).\n",
    "\n",
    "* Kernel-specific parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, the predict method of the SVC class is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Fill in the occurences to make prediction on the testing set (X_test) \n",
    "y_pred = ...(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confusion matrix* measure is the most commonly used metric for classification tasks. Scikit-Learn's metrics library contains the confusion_matrix method, which can be readily used to find out the values for these important metrics.   \n",
    "the confusion matrix that essentially is a *two-dimensional table* where the classifier model is on one axis (vertical), and ground truth is on the other (horizontal) axis, as shown below. Either of these axes can take two values (as depicted)   \n",
    "\n",
    "Model says \"+\" | Model says \"-\" | Ground truth\n",
    "---------------|----------------|-----------\n",
    "`True positive`|`False negative`|Actual: \"+\"\n",
    "`False positive`|`True negative`|  Actual: \"-\"\n",
    "\n",
    "> The goal is to create a confusion matrix in order to know the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a) fill in the occurences to import confusion_matrix method from sklearn.metrics\n",
    "\n",
    "from ... import ...  \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "There are two possible predicted classes: \"1\" (i.e positive cell) and \"0\" (i.e negative cell).\n",
    "\n",
    "    a) How many positives cells are true ?   \n",
    "    b) How many negatives cells are true ?    \n",
    "    c) How many positives cells are false ?     \n",
    "    d) How many negatives cells are false ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Rates as computed from the confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Accuracy**: Overall, how often is the classifier correct? Calculate the accuracy of the model in percentage   \n",
    "     $Accuracy = (\\frac{TP+TN}{TP+TN+FP+FN})*100$   \n",
    "     $Accuracy = ... $%\n",
    " \n",
    "b) **Misclassification Rate**: Overall, how often is it wrong? Calculate the \"error rate\" of the model in percentage\n",
    "    $Error Rate = (\\frac{FP+FN}{TP+TN+FP+FN})*100$   \n",
    "    $Error Rate = ... $%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Comparison between different kernel for no linear classification\n",
    "\n",
    "> We will implement polynomial, Gaussian, and sigmoid kernels to see which one works better for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Replace the 'linear' kernel parameter from the SVC class by 'poly'\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Make predictions on the testing set\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) create a confusion matrix to evaluate the accuracy\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) calculate the accuracy and the error rate of the polynomial model.    \n",
    "Accuracy = ...%     \n",
    "Eror rate = ... %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Now let's repeat the same steps for *Gaussian* (kernel = 'rbf') and *sigmoid* kernels (kernel = 'sigmoid'). Which kernel work better for our problem ?\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "From the result above If we compare the performance of the different types of kernels we can clearly see that the sigmoid kernel performs the worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Make prediction on new dataset (unlabel)\n",
    "\n",
    "> the goal is to predict unlabel dataset with the best classifier run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) importing the new dataset (file: unlabel_dataset.csv)\n",
    "new_data = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) print the 8 rows of new_data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) drop unrelevant features like 'Dose', 'Well', 'ImageNumber', 'ObjectNumber'\n",
    "new_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) prediction on the new_data\n",
    "new_pred = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
